---
title: "R Notebook for Thermal Conditions Analysis"
output: html_notebook
---

```{r}
##### PRE-AMBLE: 


##### Setup: pre- (condition 0) and post-retrofit (condition 1) indoor thermal comfort are each dependent on the independent variable outdoor temperature, for each building. 
##### Goal: 
    # 1) we want to know if pre- and post-retrofit (condition 0 and 1) are significantly different from one another
    # 2) we want to visualize each of the pre- and post-retrofit thermal comfort (on y axis) versus outdoor temp (x axis) on same graph
##### Approach: have a global model that codes for condition 0 and condition 1 as variables, i.e., 'dummy variable', always in response to outdoor temp variable; then look for 'effect size' of condition 0 versus condition 1... 
    # 3) repeat steps 1 and 2 for each building: because they had different retrofit actions and other unmeasured differences
```


```{r} 
##### LIBRARIES:


library(readstata13) #to read in old stata file(s) with thermal and temp data
library(readr) #to read csv files
library(tidyverse) #for everything 
library(dplyr) #for everything 
```

```{r}
##### PREP RAW DATA:


##### Outline of steps in this chunk of code:
    # 1) Get outdoor temp by date & clean it up into a dataframe with date, temp 
    # 2) Get indoor thermal comfort by date 
    # 3) Categorize outdoor and indoor data into pre and post  
    # 4) Make a single dataframe with columns: pre/post, outdoor temp, indoor thermal condition, building, suite*, date* 
    #   *n.b. suite and date will be useful for quick checks and other possible investigations of interest e.g., matching survey data with thermal conditions 


##### Step 1) Get outdoor temp by date:

WeatherDataFiles <-
  list.files("./RawData_doNotUpload/", pattern = ".csv", full.names=TRUE, recursive = FALSE) %>%
  lapply(
    read_csv, 
      skip=24, # Skip meta-data rows
      col_types = '_iii_____d_________________')%>% #choose only columns of interest
  bind_rows()




##### Step 2) Get indoor conditions by date and building:
Sensordata <- 
  read.dta13(
    choose.files()) # Load LTcomplete_weekly_collapsed.dta, which should be in a private folder i.e., NOT PUBLIC on Github
  
# Data Check: for each building, how many suites were measured? and for each how many measurements? 
  
Sensordata$murb <-
     str_extract(Sensordata$locID,".{1,3}") # Create a column for building
# Group data by building and by suite
Check <-
  Sensordata %>%
  count(locID)
  
# Count number of individual suites
# Count number of rows for each unique suite
 


  

##### 3) Categorize outdoor and indoor data into pre and post: 

```


Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
