---
title: "R Notebook for Thermal Conditions Analysis"
output: html_notebook
---

```{r}
##### PRE-AMBLE: 


##### Setup: pre- (condition 0) and post-retrofit (condition 1) indoor thermal comfort are each dependent on the independent variable outdoor temperature, for each building. 
##### Goal: 
    # 1) we want to know if pre- and post-retrofit (condition 0 and 1) are significantly different from one another
    # 2) we want to visualize each of the pre- and post-retrofit thermal comfort (on y axis) versus outdoor temp (x axis) on same graph
##### Approach: have a global model that codes for condition 0 and condition 1 as variables, indoor conditions always in response to outdoor temp variable; then look for 'effect size' of condition 0 versus condition 1... 
    # 3) repeat steps 1 and 2 for each building: because they had different retrofit actions and other unmeasured differences

# other questions... did it impact variance ? within a suite / across suites? (e.g., besides pure mean change...need to check normality/mean/variance of each day across all suites, and check...how to check variance of )
```


```{r} 
##### LIBRARIES:


library(readstata13) #to read in old stata file(s) with thermal and temp data
library(readr) #to read csv weather files
library(tidyverse) #for everything 
library(dplyr) #for everything 
library (lubridate) # for aligning dates
```



```{r}
##### PREP RAW DATA:
##### Outline of steps in this chunk of code:
    # 1) Get outdoor temp by date & clean it up into a dataframe with date, temp, and "pre"/"post" 
    # 2) Get indoor thermal comfort by date, and add "pre"/"post" 
    # 3) Reconcile two different ways of dating outdoor and indoor  
    # 4) Make a single dataframe with columns: pre/post, outdoor temp, indoor thermal condition, building, suite*, date* 
        # *n.b. suite and date will be useful for quick checks and other possible investigations of interest e.g., matching survey data with thermal conditions 
        #  n.b. Pre-retrofit monitoring: weeks 2872 to 2924 (April 1 2015 - April 1 2016)
        #  n.b. Post-retrofit monitoring: weeks 2970 to 3021, (February 15 2017-February 15 2018)


##### Step 1) Get outdoor temp by date:
WeatherRaw <-
    list.files("./RawData_doNotUpload/", pattern = ".csv", full.names=TRUE, recursive = FALSE) %>%
    lapply(
        read_csv, 
        skip=24, # Skip meta-data rows
        col_types = '_iii_____d_________________')%>% #choose only columns of interest
    bind_rows()
# Match "week" i.d. from sensor data to averages of weather station data
  # Start date of "week" is x-3 (e.g., week 2873 centered at 2015/04/05 starts on 04/02)
  # Calculate mean for each "week", beginning on corresponding "start date"+6 inclusive
WeatherCleaned <-
    WeatherRaw %>%
    rowwise() %>%
    mutate(
        date_merged = as.Date(
            paste(Year,Month,Day, sep = "-"))) %>%
    select(date_merged,`Mean Temp (Â°C)`)

#assign each date to a 'week', then group by week and average
    
    
    

##### Step 2) Get indoor conditions by date and building into a dataframe:
SensorRaw <- 
    read.dta13(choose.files()) # Load LTcomplete_weekly_collapsed.dta, which should be in a private folder i.e., NOT PUBLIC on Github

SensorRaw$murb <- # Create a column for building
    substr(SensorRaw$locID,1,3) 
 
Check <- # Data Quick Check: for each building of interest... 
    SensorRaw %>%
    filter(murb %in% c("mr1","mr2","mr6","mr7")) %>%
    group_by(murb) %>%
    summarize(n_obs_allData = sum(!is.na(murb)),# how many measurements?
        n_obs_pre = sum(date %within% interval(ymd("2015-04-01"),ymd("2016-04-01"))), #Pre-retrofit
        n_obs_post = sum(date %within% interval(ymd("2017-02-15"),ymd("2018-02-15"))), #Post-retrofit
        n_suites = n_distinct(locID), # across how many suites?
        n_obs_pre_suite_pre = sum(n_obs_pre/n_suites), # data points per suite pre
        n_obs_pre_suite_post = sum(n_obs_post/n_suites)) # data points per suite pre

SensorCleaned <- # Put the sensor data relevant columns into a new dataframe
    SensorRaw %>%
    select(murb,locID,date,tmp,com_lower,com_upper)
 

  

##### 3) Categorize outdoor and indoor data into pre and post: 

```

```{r}
# EXTRANNEOUS TIDBITS

 sapply(Sensordata,class)

```


Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
