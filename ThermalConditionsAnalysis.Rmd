---
title: "R Notebook for Thermal Conditions Analysis"
output: html_notebook
---
---
title: "R Notebook for Thermal Conditions Analysis"
output: html_notebook
---

```{r}
##### PRE-AMBLE: 

    #Setup:Pre- (condition 0) and post-retrofit (condition 1) indoor thermal comfort are each dependent on the independent variable outdoor temperature, for each building. 
    # GoalS: 
        # 1) we want to know if pre- and post-retrofit (condition 0 and 1) are significantly different from one another in terms of each: 
            # 1A MODELLED THERMAL COMFORT and 
            # 1B SURVEYED TOO HOT/TOO COLD responses
        # 2) we want to visualize each of the pre- and post-retrofit thermal comfort (on y axis) versus outdoor temp (x axis) on same graph
        # 3) repeat goals 1 and 2 for each building: because they had different retrofit actions and other unmeasured differences
    #Stats approach: have a global model that codes for condition 0 and condition 1 as variables, indoor conditions always in response to outdoor temp variable; then look for 'effect size' of condition 0 versus condition 1... 
    #Other questions to ask of the data... did it impact variance ? within a suite / across suites? (e.g., besides pure mean change...need to check normality/mean/variance of each day across all suites, and check...how to check variance of )
```


```{r} 
##### LIBRARIES:  ============
library(readstata13) #to read in old stata file(s) with thermal and temp data
library(readr) #to read csv weather files

library (lubridate) # for aligning dates
library(ggplot2) # for plotting
library(readxl) # for excel survey data files
library(glmmTMB) # for mixed effects model
#library (betareg) # for betaregression of upper_com ~ temperature and retrofit
#library(GGally) # for two-limit obit model
#library(VGAM) # for two-limit obit model
#library(zoib) # for zoib model, note: first needed to install JAGS-4.x from https://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Windows/


#library(mgcv) # for mixed effects modelling with beta regression
#library(betareg) # same as above

library(lme4)
library(MASS) # for glmmPQL for mixed effect model with quasibinomial family
library(AICcmodavg)
library(jtools) # for summ function

library(gridExtra) # for formatting summarized AIC scores
library(jtools) # for formatting output summary, i.e., using summ() of models
 
#library(Gmisc) # for visualizing survey answers...trying sankey diagrams
library(reshape2) #for ggplot of survey answers
library(ggpubr) #for using ggarrange to plot multiple figures together 
library(htmlTable) #for displaying tables, e.g., transition matrices of thermal comfort survey restults

library(interactions) # for pulling out coefficients from the mixed model
#library(data.table) # for making nice-looking tables of results
library(formattable)  # for making nice-looking tables of results

#load these last so their function names don't get overridden:
library(tidyverse) #for everything 
library(dplyr) #for everything 

```

```{r}
##### GLOBAL VARIABLES e.g., colours ============
colour1 = "#93C47D" # green 
colour2 = "#F6B26B" # orange
LikertTherm4R = c("Too cold"="#3333CC", "Just right"="#66CC99", "Too warm"="#CC0000","Don't know"="#BEBEBE") # for survey answers
plot(rep(1,4),col=LikertTherm4R ,pch=19,cex=3)
```

```{r}
##### IEQ DATA PREP ============
##### Outline of steps in this chunk of code:
    # 1)  Get indoor thermal comfort by date...
    # 2)  Get outdoor temp by date & 
    # 3)  Reconcile way of dating indoor with corresponding outdoor temps
    # 4)  Add  "pre"/"post" within a single dataframe with columns: pre/post, outdoor temp, indoor thermal condition, building, suite*, date* 
    # ...Suite and date will be useful for quick checks and other possible investigations of interest e.g., matching survey data with thermal conditions 
 

##### Step 1) Get indoor conditions by date and building into a dataframe:
dat.sensor <-
    read.dta13(choose.files())  %>% # Choose LTcomplete_weekly_collapsed-daily.dta from a NON-PUBLIC folder
    mutate(
        murb = substr(locID,1,3)) %>% # create a column for buildingID
    rename(
        tmp_in = tmp) %>% # distinguish between indoor and outdoor temperature
    dplyr::select(
        murb,locID,date,tmp_in,com_lower,com_upper,mrt,rhm) # select only information needed for next steps 

 

##### Step 2) Get outdoor temp files into one dataframe by date:
file.weather <-
    list.files("./RawData_doNotUpload/weather1", pattern = ".csv", full.names=TRUE, recursive = FALSE) %>%
    lapply(
        read_csv, 
        skip=24, # Skip meta-data rows
        col_types = '_iii_____d_________________') %>% #choose only columns of interest
    bind_rows() 
file.weather <-  #this is done in two steps because some years of weather have different underlying characteristic files
    list.files("./RawData_doNotUpload/weather2", pattern = ".csv", full.names=TRUE, recursive = FALSE) %>%
    lapply(
        read_csv, 
        col_types = '_____iii_____d_________________') %>% #choose only columns of interest
    bind_rows(.,file.weather)  

dat.weather <-
    file.weather %>%
    rowwise() %>%
    mutate(
        date = as.Date(
            paste(Year,Month,Day, sep = "-"))) %>%
    dplyr::select(date,`Mean Temp (°C)`) %>%
    rename(tmp_out =`Mean Temp (°C)`)    # rename to differentiate between indoor/outdoor 

 

##### Steps 3 & 4) Merge outdoor and indoor data and categorize into pre and post: 
    #  n.b. Pre-retrofit monitoring: weeks 2872 to 2924 (April 1 2015 - April 1 2016)
    #  n.b. Post-retrofit monitoring: weeks 2970 to 3021, (February 15 2017-February 15 2018)
dat.Sensor.Weather <- 
    merge(dat.weather, dat.sensor,by="date", all.x = TRUE, all.y = TRUE) %>% # outdoor and indoor data into one dataframe
    mutate(
        retrofit_yes = case_when (date %within% interval(ymd("2015-04-01"),ymd("2016-03-30"))~ FALSE,
                                  date %within% interval(ymd("2017-02-01"),ymd("2018-01-31"))~ TRUE,
                                  TRUE ~ NA)) %>% #default to NA if date outside the relevant intervals  
    drop_na(retrofit_yes) 
 
 
##### END OF IEQ DATA PREP
```

```{r}
##### QUICK CHECKS ============


Num_suites <-
  dat.Sensor.Weather %>%
  group_by(murb) %>%
  summarize(n_suites = n_distinct(locID))

Check_N_Observations <- # Data Quick Check: for each building of interest... 
    Day_Sensor %>%
    filter(murb %in% c("mr1","mr2","mr6","mr7")) %>%
    group_by(murb) %>%
    summarize(n_obs_allData = sum(!is.na(murb)),# how many measurements?
        n_obs_pre = sum(date %within% interval(ymd("2015-04-01"),ymd("2016-04-01"))), #Pre-retrofit
        n_obs_post = sum(date %within% interval(ymd("2017-02-15"),ymd("2018-02-15"))), #Post-retrofit
        n_suites = n_distinct(locID), # across how many suites?
        n_obs_persuite_pre = sum(n_obs_pre/n_suites), # data points per suite pre
        n_obs_persuite_post = sum(n_obs_post/n_suites)) # data points per suite pre

Check_Pre_Post_count<- # check that we have 365 days per suite of data for appropriate time period
  dat.Sensor.Weather %>%
    #filter(murb %in% c("mr1","mr2","mr6","mr7")) %>%
    group_by(murb,retrofit_yes) %>%
    summarise(n_days_recorded= n(), start=min(date), end=max(date), n_suites = n_distinct(locID), n_obs_per_suite = n_days_recorded/n_suites )
rm(Check_Pre_Post_count)
  
tmp <-
  dat.sensor %>%
  group_by(murb) %>%
  summarize(n_suites=n_distinct(locID)) 
rm(tmp)

```

```{r}
##### IEQ  MODEL PREP  ============
##### Outline of steps in this chunk of code:
    # 5) Group data by building 
    # 6) Visualize dataset (look for shape of distribution) 
  

##### Step 5)  

# Separate each murb into its own dataframe, for using as model input later:
dat.mr <- list() #Create a list in which I will save all six of the dfs
for (i in 1:7) {
    df_murb<-dat.Sensor.Weather %>%
        filter(murb==(paste0("mr",i)))  #copy all the data for a given building
        dat.mr[[i]] <- df_murb}
rm(df_murb)
rm(i)

##### Step 6)  

# Quick visualization of the distirbution of upper_com values:
dat.Sensor.Weather%>%  
      #subset(murb %in% c("mr1","mr2","mr6","mr7")) %>%
      ggplot(aes(x=com_upper,fill=retrofit_yes)) +
      scale_color_manual(values = c(colour2, colour1)) +
      scale_fill_manual(values = c(colour2, colour1)) +
      geom_histogram(position="dodge", binwidth = 0.05) + # Note: lots of values at truncated edges {0,1} 
      facet_wrap(~murb, nrow = 1) +
      theme(aspect.ratio = 0.8) 

 
# N.B. Based on visualization in step 6, and experimental design, likely a mixed model with a 'special' link function (e.g., not gaussian) will fit best

##### END OF IEQ MODEL PREP
```


```{r}
##### SIX MIXED EFFECTS REGRESSION MODELS 1, 1B, 1C, 2, 3, 4 ============

 
# MODEL 1: BASE MODEL: LME w RANDOM INTERCEPT 
# example from https://ourcodingclub.github.io/2017/03/15/mixed-models.html#second 
# mixed.lmer2 <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|sample), data = dragons) 

m1.lmer<- list() #Create a list in which I will save all models (one per building) of one type (e.g., mixed effect, logit)
m1.summary <- list()#Create a list for each summary of model
for (i in 1:7) {
    model1<- lmer(com_upper ~ tmp_out + retrofit_yes + (1|locID),
                 REML=FALSE,
                 data=dat.mr[[i]])
    m1.lmer[[i]] <- model1 
    m1.summary[[i]]<-summary(model1)
}


# MODEL 1B: SAME AS 1, but with tmp^2 
m1b.lmer<- list() #Create a list in which I will save all models (one per building) of one type (e.g., mixed effect, logit)
m1b.summary <- list()#Create a list for each summary of model
for (i in 1:7) {
    model1<- lmer(com_upper ~ poly(tmp_out,2) + retrofit_yes + (1|locID),
                 REML=FALSE,
                 data=dat.mr[[i]])
    m1b.lmer[[i]] <- model1 
    m1b.summary[[i]]<-summary(model1)
}
rm(model1) 

 
# MODEL 1C: SAME AS 1B, but interaction between retrofit and temp 
m1c.lmer<- list() #Create a list in which I will save all models (one per building) of one type (e.g., mixed effect, logit)
m1c.summary <- list()#Create a list for each summary of model
for (i in 1:7) {
    model1<- lmer(com_upper ~ I(tmp_out^2) + retrofit_yes*tmp_out + (1|locID),
                 REML=FALSE,
                 data=dat.mr[[i]])
    m1c.lmer[[i]] <- model1 
    m1c.summary[[i]]<-summary(model1)
}

rm(model1) 

# MODEL 2: RANDOM INTERCEPT + FAMILY: BINOMIAL
# example from https://www.rdocumentation.org/packages/MASS/versions/7.3-51.4/topics/glmmPQL
# summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID, family = binomial, data = bacteria))}


m2.glmer.bin<- list() #Create a list in which I will save all models (one per building) of one type (e.g., mixed effect, logit)

m2.glmer.bin[[1]] <-glmmTMB(com_upper ~ tmp_out + I(tmp_out^2) + retrofit_yes + (1|locID), dat.mr[[1]],
                            family=list(family="binomial",
                                        link="logit"))
m2.glmer.bin[[2]] <-glmmTMB(com_upper ~ tmp_out + I(tmp_out^2) + retrofit_yes + (1|locID), dat.mr[[2]], 
                            family=list(family="binomial",
                                        link="logit"))
m2.glmer.bin[[6]] <-glmmTMB(com_upper ~ tmp_out + I(tmp_out^2) + retrofit_yes + (1|locID), dat.mr[[6]], 
                            family=list(family="binomial",
                                        link="logit"))
m2.glmer.bin[[7]] <-glmmTMB(com_upper ~ tmp_out + I(tmp_out^2) + retrofit_yes + (1|locID), dat.mr[[7]], 
                            family=list(family="binomial",
                                        link="logit"))

# MODEL 3: RANDOM INTERCEPT + FAMILY: QUASIBINOMIAL
# Note: glmmPQL and glmer don't support quasibinomial, only glmmPQL() of package MASS. And random effects syntax is different...  random=~1|boite 
# example from https://statistique-et-logiciel-r.com/introduction-aux-glmm-avec-donnees-de-proportion/
# example glmmPQL1 <- glmmPQL(y~trt, random=~1|boite, family=quasibinomial, data=mydata)

m3.glmer.qb<- list() #Create a list in which I will save all models (one per building) of one type (e.g., mixed effect, logit)
for (i in 1:7) {
    model1<- glmmPQL(com_upper ~ tmp_out + retrofit_yes, random =~ 1|locID, 
                     family=quasibinomial, 
                     data= dat.mr[[i]])
    m3.glmer.qb[[i]] <- model1  
}
rm(model1)

 
# Anova and AIC and AICc not available for this model fit (quasi-binomial) 
overdisp_fun <- function(model) { # from https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html
    rdf <- df.residual(model)
    rp <- residuals(model,type="pearson")
    Pearson.chisq <- sum(rp^2)
    prat <- Pearson.chisq/rdf
    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

overdisp_fun(m3.glmer.qb) # doesn't work because can't extract the residuals in the usual way... try a custom function:
# Can use AICcCustom(logL, K, return.K = FALSE, second.ord = TRUE, nobs = NULL, c.hat = 1)
# glmmPQL doesn't report the log-likelihood however it is the same as with the binomial family fit, so we will extract the loglikelihood from that and keep the dispersion parameter from the quasi-binomial model 
# logLik = -2668.5, 
AICcCustom(-2668.5, 3, return.K = FALSE, second.ord = TRUE, nobs = 5834, c.hat = 1) # AIC 5343.004
# Can plot the residuals: 
qqnorm(m3.glmer.qb$residuals)
qqline(m3.glmer.qb$residuals)

# Arguments in AICcCustom: 
# logL the value of the model log-likelihood.
# K the number of estimated parameters in the model.
# return.K logical. If FALSE, the function returns the information criterion specified. If TRUE, the function returns K (number of estimated parameters) for a given model.
# second.ord logical. If TRUE, the function returns the second-order Akaike information criterion (i.e., AICc).
# nobs the sample size required to compute the AICc or QAICc.
# c.hat value of overdispersion parameter (i.e., variance inflation factor) such as that obtained from c_hat. Note that values of c.hat different from 1 are only appropriate for binomial GLMâs with trials > 1 (i.e., success/trial or cbind(success, failure) syntax), with Poisson GLMâs, single-season or dynamic occupancy models.  c.hat > 1, AICcCustom will return the quasi-likelihood analogue of the information criterion requested.


 
# MODEL 4: BETA MIXED MODEL (If possible, with Random Intercept! e.g., ...may have to transform data to (0,1)
# example from: https://stats.stackexchange.com/questions/233366/how-to-fit-a-mixed-model-with-response-variable-between-0-and-1 
# example glmmTMB(p ~ a+b+c + (1|subject), myData, family=list(family="beta",link="logit"))}
# To use beta, we must first transform [0,1] to (0,1):  


# first transform the com_upper response variable:
# length(dat.Sensor.Weather$com_upper) is > 28000 and under the transformation it produces numbers too small... let n = 10000
inputData <- 
    dat.Sensor.Weather %>%
        subset(murb=="mr1") %>%
        mutate( # transform y=upper_com s.t. (y * (nâ1) + 0.5) / n , where n is the sample size
           trans_com = (com_upper*10000-1)+0.5)/10000  
        

m4.glmer.beta<-glmmTMB(trans_com ~ tmp_out + retrofit_yes + (1|locID), inputData, family=list(family="beta",link="logit"))
summary(model)

 


```


```{r}
#####  MODEL COMPARISON AND EVALUATION: CHOOSE MODEL 1C ============

# Build a table with AIC and QQ plots for each model (3 models and 4 buildings each, also the average AIC for a given model)

# MODEL 1: BASE MODEL: LME w RANDOM INTERCEPT 
df = NULL
for (k in c(1,2,6,7)) {
      model_name = "m1.lmer"
      murb_ID = paste("mr",k)
      AIC_value = AIC(m1.lmer[[k]])
      df = rbind(df, data.frame(model_name,murb_ID,AIC_value))
      qqnorm(resid(m1.lmer[[k]]), 
          main = paste("MODEL 1 (Gaussian) Q-Q Plot Murb",k),
          xlab = "Theoretical Quantiles", 
          ylab = "Sample Quantiles")
      qqline(resid(m1.lmer[[k]]))}


# MODEL 1B: SAME AS 1, but with tmp^2 
for (k in c(1,2,6,7)) {
      model_name = "m1b.lmer"
      murb_ID = paste("mr",k)
      AIC_value = AIC(m1b.lmer[[k]])
      df = rbind(df, data.frame(model_name,murb_ID,AIC_value))
      qqnorm(resid(m1b.lmer[[k]]), 
          main = paste("MODEL 1B (Gaussian Poly) Q-Q Plot Murb",k),
          xlab = "Theoretical Quantiles", 
          ylab = "Sample Quantiles")
      qqline(resid(m1b.lmer[[k]]))}

# MODEL 1C: SAME AS 1B, but with interaction with tmp  
for (k in c(1,2,6,7)) {
      model_name = "m1c.lmer"
      murb_ID = paste("mr",k)
      AIC_value = AIC(m1c.lmer[[k]])
      df = rbind(df, data.frame(model_name,murb_ID,AIC_value))
      qqnorm(resid(m1c.lmer[[k]]), 
          main = paste("MODEL 1C (Gaussian Poly w Interaction Term) Q-Q Plot Murb",k),
          xlab = "Theoretical Quantiles", 
          ylab = "Sample Quantiles")
      qqline(resid(m1c.lmer[[k]]))}

# MODEL 2: SAME AS 1B, but with Binomial family
for (k in c(1,2,6,7)) {
      model_name = "m2.glmer.bin"
      murb_ID = paste("mr",k)
      AIC_value = AIC(m2.glmer.bin[[k]])
      df = rbind(df, data.frame(model_name,murb_ID,AIC_value))
      qqnorm(resid(m2.glmer.bin[[k]]), 
          main = paste("MODEL 2 (Binomial) Q-Q Plot Murb",k),
          xlab = "Theoretical Quantiles", 
          ylab = "Sample Quantiles")
      qqline(resid(m2.glmer.bin[[k]]))}


# MODEL 3: SAME AS 1B, but with Quasi-Binomial family
for (k in c(1,2,6,7)) {
      model_name = "m3.glmer.qb"
      murb_ID = paste("mr",k)
      ll=logLik(m2.glmer.bin[[k]])
      AIC_value = AICcCustom(ll, 3, return.K = FALSE, second.ord = TRUE, nobs = 5834, c.hat = 1)
      df = rbind(df, data.frame(model_name,murb_ID,AIC_value))
      qqnorm(resid(m3.glmer.qb[[k]]), 
          main = paste("MODEL 3 (Quasi-Binomial) Q-Q Plot Murb",k),
          xlab = "Theoretical Quantiles", 
          ylab = "Sample Quantiles")
      qqline(resid(m3.glmer.qb[[k]]))} 


t.AIC.scores <-  # make a table with AIC scores for each model 
  df %>% 
  group_by(model_name) %>%
  summarize(AIC_average = mean(AIC_value)) # (take average across all murbs, for brevity - minimum is same for all murbs)
pdf("data_output.pdf", height=11, width=8.5)
grid.table(t.AIC.scores )
dev.off()

      
# Check residuals if we used a lm   
model_check <- lm(dat.Sensor.Weather$com_upper ~ dat.Sensor.Weather$tmp_out + dat.Sensor.Weather$retrofit_yes) # x is tmp_out and y is com_upper
qqnorm(model_check$residuals)
qqline(model_check$residuals)
hist(model_check$residuals) ## problem is that residuals are not normally distributed


# Check whether 
qqnorm(resid(mixed.lmer1))
qqline(resid(mixed.lmer1)) # doesn't look great at edges... change to a quasi-binomial? 

```


```{r}
# SUMMARIZE AND VISUALIZE RESULTS OF MODEL 1c ============

# SUMMARIZE
summ(m1c.lmer[[5]])
summary(m1c.lmer[[5]])
anova(m1c.lmer[[5]])

# VISUALIZE
ii=5
(mm_plot <- ggplot(dat.mr[[ii]], aes(x = tmp_out, y = com_upper, colour = retrofit_yes)) +
      facet_wrap(~locID, nrow=2) +   # a panel for each suite
      geom_point(alpha = 0.2) +
      theme_classic() +
      geom_line(data = cbind(dat.mr[[ii]], pred = predict(m1c.lmer[[ii]])), aes(y = pred), size = 1) +  # adding predicted line from mixed model 
      theme(legend.position = "bottom") +   
      scale_color_manual(values = c(colour2, colour1))+
      ylim(0,1)
)



# coef(m1c.lmer[[1]])

```


```{r}

##### SURVEY DATA: PROCESS RAW FILES ======
    # 7)  Organize survey data from pre and post: gather into one dataframe
    # 8)  Create a model for survey data

#Import raw data, from pre an post surveys:
file.surv.pre <- 
      read_xlsx(choose.files(),sheet = "Master", range = cell_cols("A:GK"))  #Pre-retrofit survey data:8203 Occupant Air Quality Study Analysis v2 
file.surv.post <- read_xlsx(choose.files(),sheet = "A1") # Post-retrofit survey data: 9816_Onsite_Final Data2_Cleaned


# Clean up raw data, e.g., Focus on relevant columns:
dat.surv.pre <-
    file.surv.pre[c(1,5:7,53:64)] %>% #Keep ResponseID, building, suite ID, and answers to thermal comfort questions
    rename(First_survey = First_Survey) %>%
    mutate (First_survey = TRUE)   #Make logical variable for pre/post distinction
dat.surv.post <- 
    file.surv.post[c(9:10,13,15,61:72)] %>% 
    rename (ResponseID = occupant_import_dat_ResponseID) %>%
    mutate (Second_survey = TRUE) %>% 
    rename (Building = AptNm) %>%  # rename to match pre-retrofit data 
    rename (Suite = occupant_import_dat_Resp_Info_Suite) %>%  # rename to match pre-retrofit data 
    mutate (Suite = str_pad(Suite, 4, pad = "0")) %>%  # format with leading zero if missing
    mutate (Suite_coded = chartr("0123456789", "abcdefghij",  # code the last two digits as alphas
                                 substr(Suite,3,4))) %>%
    mutate (CODE = paste0("mr",Building,"_", substr(Suite,1,2),Suite_coded)) # create CODE variable matching pre-retrofit
 
    
# Merge Survey data into one dataframe:
dat.surv.all <-
    merge(dat.surv.pre , dat.surv.post, 
          by = c("ResponseID","CODE","Building"), 
          all = TRUE) %>%
    subset(select= -c(Suite_coded,Suite,Building)) %>% # get ride of unused columns
    mutate( murb = substr(CODE,1,3)) %>% # add a building column for grouping, and with a name that matches sensor dataframe
    dplyr::select(ResponseID,CODE,numbed,First_survey,Second_survey, everything()) #re-order columns for ease of reading

rm(dat.surv.pre,dat.surv.post)
##### END OF SURVEY DATA PREP

```

```{r}
##### SURVEY DATA: GROUP THERMAL COMFORT ANSWERS ========

# Interpret the survey answers into categories of "Too Cold", "Too Warm" or "Just Rignt", or "Don't Know"
# Reminder of labels in survey codebook: Too cold==1, Just right==2, Too warm ==3, Don't Know ==4.

#------------------
# SUMMER
#------------------
dat.surv.all <-
    dat.surv.all %>%
    mutate ( # Create a new column for respondants that are too warm, in the summer
        Pre_S_warm = case_when( 
            Q8a_Summer==3  ~ 1, # Bachelor Apartments
            Q8b_Summer_1==3 | Q8b_Summer_2== 3 ~ 1, # One bedroom Apartments
            Q8c_Summer_2==3 | Q8c_Summer_3==3 ~ 1, # Family Apartments
            is.na(First_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>% # Add Zeros to rest
    mutate ( # Create a new column for respondants that are too cold, in the summer
        Pre_S_cold = case_when(
            Q8a_Summer==1  ~ 1, # Bachelor Apartments
            Q8b_Summer_1==1 | Q8b_Summer_2== 1 ~ 1, # One bedroom Apartments
            Q8c_Summer_2==1 | Q8c_Summer_3==1 ~ 1, # Family Apartments
            is.na(First_survey)  ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>% 
    mutate ( # Create a new column for respondants that are just right, in the summer
        Pre_S_just.right = case_when(
            Q8a_Summer==2  ~ 1, # Bachelor Apartments
            Q8b_Summer_1==2 & Q8b_Summer_2== 2 ~ 1, # One bedroom Apartments
            Q8c_Summer_2==2 & Q8c_Summer_3==2 ~ 1, # Family Apartments
            is.na(First_survey)  ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0))  %>%
    mutate ( # Create a new column for respondants that "don't know", in the summer
        Pre_S_DK = case_when(
            Q8a_Summer==4  ~ 1, # Bachelor Apartments
            Q8b_Summer_1==4 & Q8b_Summer_2== 4 ~ 1, # One bedroom Apartments
            Q8c_Summer_2==4 & Q8c_Summer_3==4 ~ 1, # Family Apartments
            is.na(First_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%
    mutate ( # Create a new column for respondants that are too warm, in the summer
        Post_S_warm = case_when( 
            S8A==3  ~ 1, # Bachelor Apartments
            S8Br1==3 | S8Br2== 3 ~ 1, # One bedroom Apartments
            S8Cr2==3 | S8Cr3==3 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a new column for respondants that are too cold, in the summer
        Post_S_cold = case_when( 
            S8A==1  ~ 1, # Bachelor Apartments
            S8Br1==1 | S8Br2== 1 ~ 1, # One bedroom Apartments
            S8Cr2==1 | S8Cr3==1 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%   # Add Zeros to rest
    mutate ( # Create a new column for respondants that are just right, in the summer
        Post_S_just.right= case_when( 
            S8A==2  ~ 1, # Bachelor Apartments
            S8Br1==2 & S8Br2== 2 ~ 1, # One bedroom Apartments
            S8Cr2==2 & S8Cr3==2 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a new column for respondants that "are just right "Don't know", in the summer
        Post_S_DK= case_when( 
            S8A==4  ~ 1, # Bachelor Apartments
            S8Br1==4 & S8Br2== 4 ~ 1, # One bedroom Apartments
            S8Cr2==4 & S8Cr3==4 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a column that is a factor for all summer thermal comfort pre-retrofit
        Pre_Summer = as.factor(
                        case_when(
                            Pre_S_warm == 1 ~ "Too warm",
                            Pre_S_just.right == 1 ~ "Just right",
                            Pre_S_cold == 1 ~ "Too cold",
                            Pre_S_DK == 1 ~ "Don't know"))) %>%
    mutate ( # Create a column that is a factor for all summer thermal comfort post-retrofit
        Post_Summer = as.factor(
                        case_when(
                            Post_S_warm == 1 ~ "Too warm",
                            Post_S_just.right == 1 ~ "Just right",
                            Post_S_cold == 1 ~ "Too cold",
                            Post_S_DK == 1 ~ "Don't know")))

#------------------
# WINTER 
#------------------
 
dat.surv.all <-
    dat.surv.all %>%
    mutate ( # Create a new column for respondants that are too warm, in the summer
        Pre_W_warm = case_when( 
            Q8a_Winter==3  ~ 1, # Bachelor Apartments
            Q8b_Winter_1==3 | Q8b_Winter_2== 3 ~ 1, # One bedroom Apartments
            Q8c_Winter_2==3 | Q8c_Winter_3==3 ~ 1, # Family Apartments
            is.na(First_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>% # Add Zeros to rest
    mutate ( # Create a new column for respondants that are too cold, in the summer
        Pre_W_cold = case_when(
            Q8a_Winter==1  ~ 1, # Bachelor Apartments
            Q8b_Winter_1==1 | Q8b_Winter_2== 1 ~ 1, # One bedroom Apartments
            Q8c_Winter_2==1 | Q8c_Winter_3==1 ~ 1, # Family Apartments
            is.na(First_survey)  ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>% 
    mutate ( # Create a new column for respondants that are just right, in the summer
        Pre_W_just.right = case_when(
            Q8a_Winter==2  ~ 1, # Bachelor Apartments
            Q8b_Winter_1==2 & Q8b_Winter_2== 2 ~ 1, # One bedroom Apartments
            Q8c_Winter_2==2 & Q8c_Winter_3==2 ~ 1, # Family Apartments
            is.na(First_survey)  ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0))  %>%
    mutate ( # Create a new column for respondants that "don't know", in the summer
        Pre_W_DK = case_when(
            Q8a_Winter==4  ~ 1, # Bachelor Apartments
            Q8b_Winter_1==4 & Q8b_Winter_2== 4 ~ 1, # One bedroom Apartments
            Q8c_Winter_2==4 & Q8c_Winter_3==4 ~ 1, # Family Apartments
            is.na(First_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%
    mutate ( # Create a new column for respondants that are too warm, in the summer
        Post_W_warm = case_when( 
            S8Ai==3  ~ 1, # Bachelor Apartments
            S8Bir1==3 | S8Bir2== 3 ~ 1, # One bedroom Apartments
            S8Cir2==3 | S8Cir3==3 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a new column for respondants that are too cold, in the summer
        Post_W_cold = case_when( 
            S8Ai==1  ~ 1, # Bachelor Apartments
            S8Bir1==1 | S8Bir2== 1 ~ 1, # One bedroom Apartments
            S8Cir2==1 | S8Cir3==1 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%   # Add Zeros to rest
    mutate ( # Create a new column for respondants that are just right, in the summer
        Post_W_just.right= case_when( 
            S8Ai==2  ~ 1, # Bachelor Apartments
            S8Bir1==2 & S8Bir2== 2 ~ 1, # One bedroom Apartments
            S8Cir2==2 & S8Cir3==2 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a new column for respondants that "are just right "Don't know", in the summer
        Post_W_DK= case_when( 
            S8Ai==4  ~ 1, # Bachelor Apartments
            S8Bir1==4 & S8Bir2== 4 ~ 1, # One bedroom Apartments
            S8Cir2==4 & S8Cir3==4 ~ 1, # Family Apartments
            is.na(Second_survey) ~ NA_real_, # Make sure only counting pre-retrofit respondants
            TRUE ~ 0)) %>%  # Add Zeros to rest
    mutate ( # Create a column that is a factor for all summer thermal comfort pre-retrofit
        Pre_Winter = as.factor(
                        case_when(
                            Pre_W_warm == 1 ~ "Too warm",
                            Pre_W_just.right == 1 ~ "Just right",
                            Pre_W_cold == 1 ~ "Too cold",
                            Pre_W_DK == 1 ~ "Don't know"))) %>%
    mutate ( # Create a column that is a factor for all summer thermal comfort post-retrofit
        Post_Winter = as.factor(
                        case_when(
                            Post_W_warm == 1 ~ "Too warm",
                            Post_W_just.right == 1 ~ "Just right",
                            Post_W_cold == 1 ~ "Too cold",
                            Post_W_DK == 1 ~ "Don't know")))


##### END OF SURVEY DATA: GROUP THERMAL COMFORT ANSWERS
```



```{r}

##### SURVEY DATA: VISUALIZE THERMAL COMFORT RESULTS ============
 
#------------------
# VISUALIZATION 
#------------------
 
# make the plot for Summer
plot.S<-
    dat.surv.all %>%
    select(murb,Pre_Summer,Post_Summer) %>%
    rename(Pre = Pre_Summer, Post = Post_Summer) %>%
    melt(id="murb")%>%
    na.omit() %>%
    ggplot(aes(x=variable,fill=value)) +
        geom_bar(position="stack") +
        scale_fill_manual(values=LikertTherm4R, 
                          name = "Answers", 
                          drop=FALSE) +
        facet_grid(.~murb) +
        #theme_minimal() +
        labs(x="How comfortable are you in the summer months?", y="Count\n") + 
        theme(panel.grid.major=element_blank())

# make the plot for Winter
plot.W<-
    dat.surv.all %>%
    select(murb,Pre_Winter,Post_Winter) %>%
    rename(Pre = Pre_Winter, Post = Post_Winter) %>%
    melt(id="murb")%>%
    na.omit() %>%
    ggplot(aes(x=variable,fill=value)) +
        geom_bar(position="stack") +
        scale_fill_manual(values=LikertTherm4R, 
                          name = "Answers", 
                          drop=FALSE) +
        facet_grid(.~murb) +
        #theme_minimal() +
        labs(x="How comfortable are you in the winter months?", y="count\n") + 
        theme(panel.grid.major=element_blank())


p<- ggarrange(plot.S, plot.W, ncol=2, nrow=1, common.legend = TRUE, legend="right")
#annotate_figure(p, top=text_grob("How Comfortable are you in different rooms of your apartment?"))
ggsave(path="plots_doNotUpload", filename="results_2.pdf", width = 10, height = 4) 
rm(p)

# Make a transition matrix showing the movement between thermal comfort pre and post
trn_mtrx_summer <-
  with(dat.surv.all,
       table(Pre_Summer, 
             Post_Summer)) 
htmlTable(trn_mtrx_summer, title = "Summer Pre/Post", ctable = TRUE)


trn_mtrx_winter <-
  with(dat.surv.all,
       table(Pre_Winter, 
             Post_Winter)) 
htmlTable(trn_mtrx_winter, title = "Winter Pre/Post", ctable = TRUE)

transitionPlot(trn_mtrx_winter)

 
#------------------
# HEAT MAPS
#------------------
 
#Summer Survey Data Heatmap
df.heatmp.smmr <- as.data.frame(trn_mtrx_summer)
ggplot(data = df.heatmp.smmr , aes(x = Pre_Summer, y = Post_Summer)) +
  geom_tile(aes(fill = Freq)) +
  scale_fill_gradient(low="white", high="black") 

#Winter Survey Data Heatmap
df.heatmp.wntr <- as.data.frame(trn_mtrx_winter)
ggplot(data = df.heatmp.wntr, aes(x = Pre_Winter, y = Post_Winter)) +
  geom_tile(aes(fill = Freq)) +
  scale_fill_gradient(low="white", high="black") 
 
#------------------
# CHECKS
#------------------
check.count_responses<-
  dat.surv.all %>%
  group_by(CODE,First_survey, Second_survey) %>%
  summarize(Respondants = n_distinct(ResponseID))

dat.surv.all %>% # check that all responses are accounted for exactly once
  mutate(check_temp_PRE = Pre_S_cold+Pre_S_warm+Pre_S_just.right+Pre_S_DK) %>%
  mutate (check_temp_POST = Post_S_cold+Post_S_warm+Post_S_just.right+Post_S_DK) %>%
  select(check_temp_PRE, check_temp_POST)


# count number of monitored suites that were part of surveys
# in dat.sensor$locID and CODE, for  
check.1survey <- 
    dat.surv.all %>%
    filter( First_survey == TRUE) %>% 
    select(CODE) 
 
check.1results<- 
  dat.sensor %>%
  filter( dat.sensor$locID %in%  check.1survey$CODE) %>%
  select(locID,murb)%>%
  distinct(locID, .keep_all = TRUE) %>%
  group_by(murb) %>%
  tally()
 
check.2survey <- 
    dat.surv.all %>%
    filter( Second_survey == TRUE) %>% 
    select(CODE) 
 
check.2results<- 
  dat.sensor %>%
  filter( dat.sensor$locID %in%  check.2survey$CODE) %>%
  select(locID,murb)%>%
  distinct(locID, .keep_all = TRUE) %>%
  group_by(murb) %>%
  tally()

mr103eb<- 
  dat.surv.all %>%
  filter(CODE=="mr1_03eb" | CODE == "mr1_03ea")
 
mr5_09adb<- 
  dat.surv.all %>%
  filter(CODE=="mr5_09ad")

# tally the percentage answers, by building, for each season
table(dat.surv.all$murb,dat.surv.all$Pre_Winter) %>%
    prop.table(margin=1) %>%
    round(3) %>%
     `*`(100)

table(dat.surv.all$murb,dat.surv.all$Pre_Summer) %>%
    prop.table(margin=1) %>%
    round(3) %>%
     `*`(100)

table(dat.surv.all$murb,dat.surv.all$Post_Winter) %>%
    prop.table(margin=1) %>%
    round(3) %>%
     `*`(100)
 
table(dat.surv.all$murb,dat.surv.all$Post_Summer) %>%
    prop.table(margin=1) %>%
    round(3) %>%
     `*`(100)
 

```

```{r}

 
##### SURVEY DATA + IEQ: MATCH PREDICTED and SURVEYED COMFORT
 
# Make a dataframe to hold all important variables,
# with a list of locations, including their murb, that were in the set of sensor data 
# Add their thermal comfort for summer/winter pre/post,  for comparison between survey and sensored suites
dat.cmpr.all.rslts <-
    data.frame(CODE = unique(dat.sensor$locID)) %>%
    mutate (sensored_suite = TRUE) %>%
    merge(dat.surv.all, by = "CODE", all = TRUE) %>%
    select(CODE,murb,sensored_suite,Pre_Summer,Post_Summer,Pre_Winter, Post_Winter) %>%
    mutate(locID = as.numeric(substr(murb,3,3)))  

# make a dataframe with all the modelling coefficients for all the suites
# recall we put the results from modelling each murb(i) into the following variable names: m1c.lmer[[i]] and m1c.summary[[i]]
# use coef(m1c.lmer[[1]]), coef(m1c.summary[[1]]) and m1c.summary[[1]]$coefficients[1,2]
 
 
# collect all the conditional coefficients of each suite (e.g., random effects) and their standard deviations
dat.predicted.comf <- data.frame() 
for (i in 1:7) {  
    dat.predicted.comf  <- as.data.frame(
        ranef(m1c.lmer[[i]])) %>%
        mutate(locID= as.numeric(i)) %>%  # add coefficients from murb-level model
        mutate (murb.int= m1c.summary[[i]]$coefficients[1],
                murb.se= m1c.summary[[i]]$coefficients[1,2],
                murb.tmp2.int = m1c.summary[[i]]$coefficients[2],
                murb.tmp.int = m1c.summary[[i]]$coefficients[4],
                murb.retrofit = m1c.summary[[i]]$coefficients[3],
                murb.ret_tmp = m1c.summary[[i]]$coefficients[5]) %>%
        rename(CODE=grp) %>%   # tidy up and use self-annotating names
        select(-c(grpvar,term)) %>% 
        rename( suite.int = condval, 
                suite.sd=condsd) %>%
        mutate (suite.int = suite.int + murb.int,  # determine the suite-level intercept
                suite.CI.upr = suite.int + 1.96*suite.sd,  # and the 95% interval for suite-level intercept
                suite.CI.lwr = suite.int - 1.96*suite.sd) %>%
        bind_rows(.,dat.predicted.comf)}
rm(i)

# put predcited comfort and surveyed comfort together
dat.cmpr.all.rslts<- merge(dat.cmpr.all.rslts,
                            dat.predicted.comf, all=TRUE)
 

# find the mean temp in summer and winter
 
 # Recall dates for predicted comfort analysis were retrofit = 
  #  %within% interval(ymd("2015-04-01"),ymd("2016-03-30"))~ FALSE,
  #  %within% interval(ymd("2017-02-01"),ymd("2018-01-31"))~ TRUE
# However, here we are just finding an example temperature at which to then predict the comfort 
# (temp doesn't have to be precisesly representative of the summer/winter in question)
tmp.mn.smmr<- 
    dat.weather %>% # defined as average between June 21 and Sept 21
    filter((date(date)>="2015-06-21" & date(date)<"2015-09-21") | (date(date)>="2017-06-21" & date(date)<"2017-09-21"))  
    tmp.mn.smmr <- mean(tmp.mn.smmr$tmp_out) %>% round(round(digits=2))
 
tmp.mn.wntr<-
    dat.weather %>% # defined as average between Dec 21 and Feb 21
    filter((date(date)>="2015-12-21" & date(date)<"2016-02-21") | (date(date)>="2017-12-21" & date(date)<"2018-02-21"))  
    tmp.mn.wntr <- mean(tmp.mn.wntr$tmp_out) %>% round(round(digits=2))  
  

# Update results dataframe with predicted comfort for a typical summer and winter day
dat.cmpr.all.rslts <-
    dat.cmpr.all.rslts %>%
    filter(sensored_suite == TRUE) %>%
    mutate(
        Pre_smmr_prct = round(suite.int + murb.tmp.int*tmp.mn.smmr + murb.tmp2.int*tmp.mn.smmr, digits=2),  # add column with predicted % time comfortable
        Post_smmr_prct =  round(suite.int  + murb.tmp.int*tmp.mn.smmr + murb.tmp2.int*tmp.mn.smmr + murb.retrofit + murb.ret_tmp, digits=2), #same for post-retrofit, which has the extra terms
        Pre_wntr_prct = round(suite.int  + murb.tmp.int*tmp.mn.wntr + murb.tmp2.int*tmp.mn.wntr, digits=2), # for average summer day and average winter day
        Post_wntr_prct = round(suite.int  + murb.tmp.int*tmp.mn.wntr + murb.tmp2.int*tmp.mn.wntr + murb.retrofit + murb.ret_tmp, digits =2)) %>%
        mutate( 
            Pre_smmr_prct = case_when(Pre_smmr_prct>=1 ~ 1, TRUE ~ Pre_smmr_prct),
            Post_smmr_prct = case_when(Post_smmr_prct>=1 ~ 1, TRUE ~ Post_smmr_prct),
            Pre_wntr_prct = case_when(Pre_wntr_prct>=1 ~ 1, TRUE ~ Pre_wntr_prct),
            Post_wntr_prct = case_when(Post_wntr_prct>=1 ~ 1, TRUE ~ Post_wntr_prct))

 
# for building-level and then for suite-level:
# compare pre and post average comfort for summer and winter to the pre and post responses 
ls.results = list()
for (i in 1:7) { 
    ls.results[[i]]  <-
        dat.cmpr.all.rslts %>%
        filter (locID ==i) %>%
        select(-c(3,4,9:18))}
    

formattable(ls.results[[7]])    
     

    
# Out of interest: does variance of predicted comfort change pre/post?    
    
# make a column for delta "% responses just right" and a column for delta "predicted comfort"
 
# mini sensitivity-analysis: check other temperatures - and check extremes

# Add a column for the Murb-level Intercept Pre/Post and Suite-Intercept Pre/Post for general magnitude/direction of predicted comfort pre/post

# Also report the murb as a whole, on average, versus the occupants (i.e., not just sensored suites) of that murb


```
 
 
```{r}
########## SIDE PROJECT =============

# What variables are the best proxys for occupant's self-reported thermal comfort? 
# Check correlation between different measures of predicted thermal comfort, temperatures (i.e., average, high, low, seasonal average...), other answers on survey (e.g., number of bedrooms, building, time living in apartment, smoking, draftiness, etc.)



```
 
 
```{r}
# TRYING OUT VISUALIZATIONS OF MIXED MODELS ============

##########

library(nlme)
fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1|Subject)

newdat <- expand.grid(Sex=unique(Orthodont$Sex),
                  age=c(min(Orthodont$age),
                            max(Orthodont$age)))

library(ggplot2)
p <- ggplot(Orthodont, aes(x=age, y=distance, colour=Sex)) +
  geom_point(size=3) +
  geom_line(aes(y=predict(fm2), group=Subject, size="Subjects")) +
  geom_line(data=newdat, aes(y=predict(fm2, level=0, newdata=newdat), size="Population")) +
  scale_size_manual(name="Predictions", values=c("Subjects"=0.5, "Population"=3)) +
  theme_bw(base_size=22) 
print(p)

#//////////////# 
 
newdat <- expand.grid(retrofit_yes=unique(dat.mr[[1]]$retrofit_yes),
                  tmp_out=c(min(dat.mr[[1]]$tmp_out),
                            max(dat.mr[[1]]$tmp_out)))
 
p <- ggplot(dat.mr[[1]], aes(x=tmp_out, y=com_upper, colour=retrofit_yes)) +
  geom_point(size=3) +
  geom_line(aes(y=predict(m1c.lmer[[1]]), group=locID, size="Suites")) +
  geom_line(data=newdat , aes(y=predict(m1c.lmer[[1]], level=0, newdata=newdat), size="MURB 1 Population")) +
  scale_size_manual(name="Predictions", values=c("Suites"=0.2, "Population"=3)) +
  theme_bw(base_size=22) 
print(p)
 
summary(m1c.lmer[[1]]) 

summary(m1c.lmer[[1]])
anova(m1c.lmer[[1]])
fixef(m1c.lmer[[1]])


 # For lmer.1 For mr1, Notice locID explains 0.0599/(0.0599+0.0953) = 38.5% of variation that's "leftover" after the variance explained by our fixed effects... perform this calculation for each 
summary(m1.lmer[[1]])
 

# VISUALIZE
(mm_plot <- ggplot(inputData_mr1, aes(x = tmp_out, y = com_upper, colour = retrofit_yes)) +
      facet_wrap(~locID, nrow=2) +   # a panel for each suite
      geom_point(alpha = 0.2) +
      theme_classic() +
      geom_line(data = cbind(inputData_mr1, pred = predict(mixed.lmer1)), aes(y = pred), size = 1) +  # adding predicted line from mixed model 
      theme(legend.position = "bottom") +   
      scale_color_manual(values = c(colour2, colour1))+
      ylim(0,1)
)
 



```


